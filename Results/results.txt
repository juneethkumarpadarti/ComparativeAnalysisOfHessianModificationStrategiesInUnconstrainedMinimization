
==================================================
ROSENBROCK FUNCTION
==================================================

strategy_1

Optimized parameters: [-0.9932861   0.99665107  0.99833032  0.99916774  0.9995852   0.99979328
  0.99989698  0.99994866  0.99997441  0.99998725  0.99999365  0.99999683
  0.99999842  0.99999921  0.99999961  0.9999998   0.9999999   0.99999995
  0.99999998  0.99999999  0.99999999  1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          1.          1.          1.
  1.          1.          1.          0.99999999  0.99999998  0.99999996
  0.99999992  0.99999984  0.99999967  0.99999933  0.99999865  0.99999726
  0.99999447  0.99998882  0.99997741  0.99995437]
Iterations: 1000
Function evaluations: 5896
Final gradient norm: 4.199369125279174e-05
Algorithm halted. Maximum number of iterations reached.

==================================================     
RASTRIGIN FUNCTION
==================================================     

strategy_1

Step tolerance reached at iteration 2
Optimized parameters: [-2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08]
Iterations: 2
Function evaluations: 34
Final gradient norm: 7.8912132272887e-05
Algorithm halted. Step tolerance reached.

==================================================
RAYDAN2 FUNCTION
==================================================

strategy_1

Gradient tolerance reached at iteration 9
Optimized parameters: [-7.12191283e-17  2.43367937e-17  8.47160987e-17  4.20276106e-10
  2.05121990e-17  2.32333663e-16  3.17644131e-17  6.94627657e-17
  1.69171968e-16  3.50864198e-16  2.05121990e-17  1.18371769e-16
  2.91332664e-16 -1.05630288e-16  8.47160987e-17 -5.53708531e-17
  7.30166888e-17  2.86546624e-16  7.30166888e-17 -7.79437575e-17
  1.29566755e-16  1.42567606e-16 -3.41950468e-18  2.69947584e-16
  9.39661294e-17  2.54437712e-17  0.00000000e+00  5.87894136e-17
  1.77465785e-17  7.30166888e-17  6.36692676e-17  2.54437712e-17
  1.03937729e-17  1.03639488e-16  2.22510370e-16  8.01115828e-17
  8.47160987e-17 -4.29657578e-17  5.87894136e-17  4.28983035e-17
 -5.53708531e-17  7.30166888e-17  8.01115828e-17  6.36692676e-17
  1.51790878e-16  1.29624900e-16  3.45749628e-17  3.72097343e-17
  3.72097343e-17  3.10766621e-16  9.76491023e-17  2.05121990e-17
  7.55532114e-17  1.71764756e-16  9.76491023e-17  5.14175427e-17
  2.95013454e-17  2.69947584e-16  2.05121990e-17 -5.53708531e-17
  9.76491023e-17  4.28983035e-17  1.10300192e-16  1.51790878e-16
 -2.57664991e-17  7.15121319e-17  8.30601299e-18  5.59345238e-18
  1.69171968e-16  7.55532114e-17  8.49033897e-17 -2.64860516e-17
  2.32333663e-16  1.10300192e-16  2.68097919e-16  3.72097343e-17
  2.86546624e-16 -9.80706207e-17  1.71764756e-16  1.77465785e-17]
Iterations: 9
Function evaluations: 52
Final gradient norm: 4.2027603619634407e-10
Algorithm halted. Gradient tolerance reached.

==================================================
BEALE FUNCTION
==================================================

strategy_1

Gradient tolerance reached at iteration 28
Optimized parameters: [3.  0.5]
Iterations: 28
Function evaluations: 147
Final gradient norm: 2.189245374993112e-09
Algorithm halted. Gradient tolerance reached.

==================================================
MATYAS FUNCTION
==================================================

strategy_1

Gradient tolerance reached at iteration 2
Optimized parameters: [2.22044605e-16 2.22044605e-16]
Iterations: 2
Function evaluations: 5
Final gradient norm: 1.2560739669470211e-17
Algorithm halted. Gradient tolerance reached.

==================================================
POWELL SINGULAR FUNCTION
==================================================

strategy_1

Optimized parameters: [ 0.0020653  -0.00020653  0.00102926  0.00102927]
Iterations: 1000
Function evaluations: 6990
Final gradient norm: 4.708617118472536e-06
Algorithm halted. Maximum number of iterations reached.

==================================================
SPHERE FUNCTION
==================================================

strategy_1

Gradient tolerance reached at iteration 2
Optimized parameters: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.]
Iterations: 2
Function evaluations: 5
Final gradient norm: 0.0
Algorithm halted. Gradient tolerance reached.

==================================================
BOOTH FUNCTION
==================================================

strategy_1

Gradient tolerance reached at iteration 2
Optimized parameters: [1. 3.]
Iterations: 2
Function evaluations: 5
Final gradient norm: 3.972054645195637e-15
Algorithm halted. Gradient tolerance reached.

==================================================
STYBLINSKI TANG FUNCTION
==================================================

strategy_1

Gradient tolerance reached at iteration 11
Optimized parameters: [-2.90353403  2.74680277 -2.90353403  2.74680277 -2.90353403  2.74680277
  2.74680277  2.74680277 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277 -2.90353403
  2.74680277 -2.90353403 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277  2.74680277 -2.90353403  2.74680277 -2.90353403
  2.74680277 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277
 -2.90353403  2.74680277 -2.90353403 -2.90353403 -2.90353403  2.74680277
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277  2.74680277
 -2.90353403  2.74680277 -2.90353403 -2.90353403  2.74680277  2.74680277
  2.74680277  2.74680277 -2.90353403 -2.90353403 -2.90353403 -2.90353403
 -2.90353403 -2.90353403  2.74680277  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277  2.74680277
 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277
 -2.90353403  2.74680277  2.74680277  2.74680277]
Iterations: 11
Function evaluations: 72
Final gradient norm: 3.242214211321466e-11
Algorithm halted. Gradient tolerance reached.

==================================================
MCCORMICK FUNCTION
==================================================

strategy_1

Gradient tolerance reached at iteration 4
Optimized parameters: [-0.54719755 -1.54719755]
Iterations: 4
Function evaluations: 13
Final gradient norm: 6.578688151332449e-13
Algorithm halted. Gradient tolerance reached.

==================================================
EASOM FUNCTION

strategy_1

Gradient tolerance reached at iteration 3
Optimized parameters: [3.14159265 3.14159265]
Iterations: 3
Function evaluations: 12
Final gradient norm: 6.378949660432729e-10
Algorithm halted. Gradient tolerance reached.

==================================================
WOOD FUNCTION
==================================================

strategy_1

Step tolerance reached at iteration 1
Optimized parameters: [-1.  1.  1.  1.]
Iterations: 1
Function evaluations: 15
Final gradient norm: 4.0
Algorithm halted. Step tolerance reached.

==================================================
HELICAL VALLEY FUNCTION
==================================================

strategy_1

Step tolerance reached at iteration 1
Optimized parameters: [1.  0.1 0.1]
Iterations: 1
Function evaluations: 15
Final gradient norm: 66.52691792104442
Algorithm halted. Step tolerance reached.

=======================================================================================================================================================================

==================================================
ROSENBROCK FUNCTION
==================================================

strategy_2

Optimized parameters: [-0.99328611  0.99665109  0.99833034  0.99916776  0.99958523  0.99979332
  0.99989702  0.99994871  0.99997447  0.99998731  0.99999372  0.99999691
  0.99999851  0.9999993   0.99999971  0.99999991  1.00000001  1.00000007
  1.0000001   1.00000012  1.00000013  1.00000014  1.00000015  1.00000015
  1.00000016  1.00000016  1.00000017  1.00000018  1.00000018  1.00000019
  1.00000019  1.0000002   1.0000002   1.00000021  1.00000021  1.00000022
  1.00000023  1.00000023  1.00000023  1.00000024  1.00000024  1.00000025
  1.00000025  1.00000026  1.00000026  1.00000027  1.00000027  1.00000027
  1.00000028  1.00000028  1.00000028  1.00000029  1.00000029  1.00000029
  1.00000029  1.0000003   1.0000003   1.0000003   1.0000003   1.00000031
  1.00000031  1.00000031  1.00000031  1.00000031  1.00000031  1.00000031
  1.00000031  1.00000031  1.00000031  1.00000031  1.00000031  1.00000031
  1.00000031  1.00000031  1.00000031  1.00000031  1.00000031  1.0000003
  1.0000003   1.0000003   1.0000003   1.00000029  1.00000029  1.00000028
  1.00000027  1.00000025  1.00000022  1.00000015  1.00000002  0.99999977
  0.99999926  0.99999825  0.99999622  0.99999214  0.99998394  0.99996748
  0.99993441  0.99986795  0.9997344   0.99946605]
Iterations: 1000
Function evaluations: 5135
Final gradient norm: 0.0006610166738267139
Algorithm halted. Maximum number of iterations reached.

==================================================
RASTRIGIN FUNCTION
==================================================

strategy_2

Step tolerance reached at iteration 3
Optimized parameters: [-7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12 -7.36170075e-12
 -7.36170075e-12 -7.36170075e-12]
Iterations: 3
Function evaluations: 48
Final gradient norm: 2.7711099543738435e-08
Algorithm halted. Step tolerance reached.

==================================================
RAYDAN2 FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 9
Optimized parameters: [ 8.56459828e-18  6.07659865e-17  3.44904338e-17  4.20276189e-10
  6.60730449e-18  1.76822513e-16  1.02908404e-16 -2.25588912e-17
  9.97830256e-17  2.39706387e-16  6.60730449e-18  3.33838746e-17
  1.21329777e-16  1.05690798e-17  3.44904338e-17  1.22698066e-17
  1.06842102e-16  2.79580625e-16  1.06842102e-16  9.55285898e-17
 -4.91233135e-17  1.42540504e-16  3.12614127e-17  2.66505240e-16
 -3.40780413e-17  1.41656687e-16  0.00000000e+00  6.91706494e-17
  5.93799411e-17  1.06842102e-16  8.09893961e-17  1.41656687e-16
  2.77410077e-17 -9.93265464e-17  1.87843006e-16  4.36823898e-17
  3.44904338e-17 -4.90339019e-17  6.91706494e-17  2.20833158e-17
  1.22698066e-17  1.06842102e-16  4.36823898e-17  8.09893961e-17
  1.96866580e-16  1.27863070e-16 -2.48410103e-17  4.59240080e-17
  4.59240080e-17  2.41269272e-16 -2.20468184e-17  6.60730449e-18
  8.59344455e-17  1.89111994e-16 -2.20468184e-17  3.74719964e-17
 -9.36640214e-17  2.66505240e-16  6.60730449e-18  1.22698066e-17
 -2.20468184e-17  2.20833158e-17  1.15504362e-16  1.96866580e-16
 -6.68454083e-18 -1.05429663e-16 -4.11336060e-17  1.30425779e-16
  9.97830256e-17  8.59344455e-17  8.31686662e-17 -3.34249456e-17
  1.76822513e-16  1.15504362e-16  2.36899998e-16  4.59240080e-17
  2.79580625e-16 -8.41860566e-17  1.89111994e-16  5.93799411e-17]
Iterations: 9
Function evaluations: 52
Final gradient norm: 4.2027625824083164e-10
Algorithm halted. Gradient tolerance reached.

==================================================
BEALE FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 86
Optimized parameters: [3.  0.5]
Iterations: 86
Function evaluations: 434
Final gradient norm: 7.662550080722606e-09
Algorithm halted. Gradient tolerance reached.

==================================================
MATYAS FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 2
Optimized parameters: [1.55431223e-15 1.44328993e-15]
Iterations: 2
Function evaluations: 5
Final gradient norm: 1.1554856477198507e-16
Algorithm halted. Gradient tolerance reached.

==================================================
POWELL SINGULAR FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 22
Optimized parameters: [ 1.37742501e-05 -1.37740141e-06  2.85882286e-06  2.85879298e-06]
Iterations: 22
Function evaluations: 127
Final gradient norm: 4.76370372838661e-09
Algorithm halted. Gradient tolerance reached.

==================================================
SPHERE FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 2
Optimized parameters: [1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16 1.11022302e-16
 1.11022302e-16 1.11022302e-16 1.11022302e-16]
Iterations: 2
Function evaluations: 5
Final gradient norm: 1.922962686383564e-15
Algorithm halted. Gradient tolerance reached.

==================================================
BOOTH FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 2
Optimized parameters: [1. 3.]
Iterations: 2
Function evaluations: 5
Final gradient norm: 3.972054645195637e-15
Algorithm halted. Gradient tolerance reached.

==================================================
STYBLINSKI TANG FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 11
Optimized parameters: [-2.90353403  2.74680277 -2.90353403  2.74680277 -2.90353403  2.74680277
  2.74680277  2.74680277 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277 -2.90353403
  2.74680277 -2.90353403 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277  2.74680277 -2.90353403  2.74680277 -2.90353403
  2.74680277 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277
 -2.90353403  2.74680277 -2.90353403 -2.90353403 -2.90353403  2.74680277
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277  2.74680277
 -2.90353403  2.74680277 -2.90353403 -2.90353403  2.74680277  2.74680277
  2.74680277  2.74680277 -2.90353403 -2.90353403 -2.90353403 -2.90353403
 -2.90353403 -2.90353403  2.74680277  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277  2.74680277
 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277
 -2.90353403  2.74680277  2.74680277  2.74680277]
Iterations: 11
Function evaluations: 68
Final gradient norm: 2.059164984796528e-11
Algorithm halted. Gradient tolerance reached.

==================================================
MCCORMICK FUNCTION
==================================================

strategy_2

Gradient tolerance reached at iteration 4
Optimized parameters: [-0.54719755 -1.54719755]
Iterations: 4
Function evaluations: 13
Final gradient norm: 6.578688151332449e-13
Algorithm halted. Gradient tolerance reached.

==================================================
EASOM FUNCTION

strategy_2

Gradient tolerance reached at iteration 3
Optimized parameters: [3.14159265 3.14159265]
Iterations: 3
Function evaluations: 12
Final gradient norm: 6.378949660432729e-10
Algorithm halted. Gradient tolerance reached.

==================================================
WOOD FUNCTION
==================================================

strategy_2

Step tolerance reached at iteration 1
Optimized parameters: [-1.  1.  1.  1.]
Iterations: 1
Function evaluations: 15
Final gradient norm: 4.0
Algorithm halted. Step tolerance reached.

==================================================
HELICAL VALLEY FUNCTION
==================================================

strategy_2

Step tolerance reached at iteration 1
Optimized parameters: [1.  0.1 0.1]
Iterations: 1
Function evaluations: 15
Final gradient norm: 66.52691792104442
Algorithm halted. Step tolerance reached.

======================================================================================================================================================================

==================================================
ROSENBROCK FUNCTION
==================================================

strategy_3

Optimized parameters: [-9.93284425e-01  9.96647784e-01  9.98325421e-01  9.99161235e-01
  9.99577085e-01  9.99783523e-01  9.99885555e-01  9.99935525e-01
  9.99959521e-01  9.99970540e-01  9.99975056e-01  9.99976294e-01
  9.99975854e-01  9.99974533e-01  9.99972723e-01  9.99970614e-01
  9.99968300e-01  9.99965821e-01  9.99963194e-01  9.99960423e-01
  9.99957506e-01  9.99954437e-01  9.99951208e-01  9.99947812e-01
  9.99944241e-01  9.99940485e-01  9.99936539e-01  9.99932397e-01
  9.99928054e-01  9.99923509e-01  9.99918758e-01  9.99913796e-01
  9.99908611e-01  9.99903180e-01  9.99897462e-01  9.99891391e-01
  9.99884881e-01  9.99877818e-01  9.99870087e-01  9.99861557e-01
  9.99852113e-01  9.99841517e-01  9.99829271e-01  9.99813903e-01
  9.99791880e-01  9.99754801e-01  9.99684626e-01  9.99543584e-01
  9.99255659e-01  9.98669968e-01  9.97489518e-01  9.95132346e-01
  9.90456748e-01  9.81236906e-01  9.63177527e-01  9.28252472e-01
  8.62445293e-01  7.44958760e-01  5.56749869e-01  3.13290178e-01
  1.04329736e-01  2.01607609e-02  1.17405658e-02  1.10181080e-02
  7.26139185e-03  9.69029834e-03  1.35306982e-02  1.09183975e-02
  6.83399114e-03  9.37873383e-03  1.36989893e-02  1.10789444e-02
  6.73495567e-03  9.35170488e-03  1.36545018e-02  1.11214888e-02
  6.97182851e-03  9.28579671e-03  1.32618258e-02  1.10630628e-02
  7.53905647e-03  9.40634286e-03  1.26194277e-02  1.09278219e-02
  8.20493930e-03  9.51370038e-03  1.19042483e-02  1.04694365e-02
  9.37925580e-03  1.00262353e-02  1.07978571e-02  9.86234630e-03
  1.01421076e-02  1.05984747e-02  9.84643442e-03  1.00820385e-02
  1.07330053e-02  9.99772778e-03  9.61168441e-03  2.88307384e-05]
Iterations: 1000
Function evaluations: 8081
Final gradient norm: 3.5687219283595835
Algorithm halted. Maximum number of iterations reached.

==================================================
RASTRIGIN FUNCTION
==================================================

strategy_3

Step tolerance reached at iteration 2
Optimized parameters: [-2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08 -2.09637118e-08
 -2.09637118e-08 -2.09637118e-08]
Iterations: 2
Function evaluations: 34
Final gradient norm: 7.8912132272887e-05
Algorithm halted. Step tolerance reached.

==================================================
RAYDAN2 FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 8
Optimized parameters: [ 9.87285701e-18 -1.04422171e-16  8.85903551e-15  3.46012101e-09
  2.79829256e-19  1.35967315e-17 -6.65909328e-17  3.23940855e-15
 -6.09584809e-17  2.51244361e-13  2.79829256e-19  2.47878147e-13
  9.19980046e-17 -6.00063845e-17  8.85903551e-15  5.64699855e-17
  2.11232675e-17 -7.22572809e-17  2.11232675e-17  7.84218109e-17
  1.93395454e-16  8.67910310e-11 -9.64261335e-18  4.87045725e-17
  1.44263809e-14  2.30355450e-14  0.00000000e+00  9.34991065e-17
  1.00676430e-16  2.11232675e-17  1.80507364e-15  2.30355450e-14
  3.89953243e-14  5.66636730e-15  2.78181877e-17  4.60520167e-17
  8.85903551e-15 -8.43989952e-17  9.34991065e-17 -5.23861820e-17
  5.64699855e-17  2.11232675e-17  4.60520167e-17  1.80507364e-15
 -8.38380129e-17  2.29589400e-14  2.08151348e-15  7.86262740e-17
  7.86262740e-17  3.81945685e-17  1.67269560e-14  2.79829256e-19
 -6.48265558e-17 -1.36906729e-17  1.67269560e-14  3.78679687e-13
  7.70334961e-15  4.87045725e-17  2.79829256e-19  5.64699855e-17
  1.67269560e-14 -5.23861820e-17  1.65768873e-14 -8.38380129e-17
  9.36969731e-17 -5.71306782e-17  4.43814559e-17  2.56506828e-13
 -6.09584809e-17 -6.48265558e-17  7.61137541e-15  2.60736696e-16
  1.35967315e-17  1.65768873e-14 -7.47097221e-17  7.86262740e-17
 -7.22572809e-17 -5.97420279e-17 -1.36906729e-17  1.00676430e-16]
Iterations: 8
Function evaluations: 37
Final gradient norm: 3.461209455949808e-09
Algorithm halted. Gradient tolerance reached.

==================================================
BEALE FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 58
Optimized parameters: [2.99999999 0.5       ]
Iterations: 58
Function evaluations: 318
Final gradient norm: 7.184305084906722e-09
Algorithm halted. Gradient tolerance reached.

==================================================
MATYAS FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 2
Optimized parameters: [2.22044605e-16 2.22044605e-16]
Iterations: 2
Function evaluations: 5
Final gradient norm: 1.2560739669470211e-17
Algorithm halted. Gradient tolerance reached.

==================================================
POWELL SINGULAR FUNCTION
==================================================

strategy_3

Optimized parameters: [ 0.00297553 -0.00029757  0.00148286  0.00148291]
Iterations: 1000
Function evaluations: 6492
Final gradient norm: 6.5942214722082535e-06
Algorithm halted. Maximum number of iterations reached.

==================================================
SPHERE FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 2
Optimized parameters: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0.]
Iterations: 2
Function evaluations: 5
Final gradient norm: 0.0
Algorithm halted. Gradient tolerance reached.

==================================================
BOOTH FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 2
Optimized parameters: [1. 3.]
Iterations: 2
Function evaluations: 5
Final gradient norm: 3.972054645195637e-15
Algorithm halted. Gradient tolerance reached.

==================================================
STYBLINSKI TANG FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 12
Optimized parameters: [-2.90353403  2.74680277 -2.90353403  2.74680277 -2.90353403  2.74680277
  2.74680277  2.74680277 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277
 -2.90353403 -2.90353403 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277 -2.90353403
  2.74680277 -2.90353403 -2.90353403  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277  2.74680277 -2.90353403  2.74680277 -2.90353403
  2.74680277 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277
 -2.90353403  2.74680277 -2.90353403 -2.90353403 -2.90353403  2.74680277
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277  2.74680277
 -2.90353403  2.74680277 -2.90353403 -2.90353403  2.74680277  2.74680277
  2.74680277  2.74680277 -2.90353403 -2.90353403 -2.90353403 -2.90353403
 -2.90353403 -2.90353403  2.74680277  2.74680277 -2.90353403 -2.90353403
 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277  2.74680277
 -2.90353403 -2.90353403  2.74680277 -2.90353403  2.74680277  2.74680277
 -2.90353403  2.74680277  2.74680277  2.74680277]
Iterations: 12
Function evaluations: 87
Final gradient norm: 7.105427357601002e-14
Algorithm halted. Gradient tolerance reached.

==================================================
MCCORMICK FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 4
Optimized parameters: [-0.54719755 -1.54719755]
Iterations: 4
Function evaluations: 13
Final gradient norm: 6.578688151332449e-13
Algorithm halted. Gradient tolerance reached.

==================================================
EASOM FUNCTION
==================================================

strategy_3

Gradient tolerance reached at iteration 3
Optimized parameters: [3.14159265 3.14159265]
Iterations: 3
Function evaluations: 12
Final gradient norm: 6.378949660432729e-10
Algorithm halted. Gradient tolerance reached.

==================================================
WOOD FUNCTION
==================================================

strategy_3

Step tolerance reached at iteration 1
Optimized parameters: [-1.  1.  1.  1.]
Iterations: 1
Function evaluations: 15
Final gradient norm: 4.0
Algorithm halted. Step tolerance reached.

==================================================
HELICAL VALLEY FUNCTION
==================================================

strategy_3

Step tolerance reached at iteration 1
Optimized parameters: [1.  0.1 0.1]
Iterations: 1
Function evaluations: 15
Final gradient norm: 66.52691792104442
Algorithm halted. Step tolerance reached.